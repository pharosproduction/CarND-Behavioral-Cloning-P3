{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(source_path):\n",
    "    filename = source_path.split('/')[-1]\n",
    "    center_path = '../data/IMG/' + filename\n",
    "    image = cv2.imread(center_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return np.expand_dims(image, axis=2)\n",
    "\n",
    "def build_generator(csv_lines, batches, batch_size):\n",
    "    sample_shape = load_image(csv_lines[0][0]).shape\n",
    "\n",
    "    while True:\n",
    "        batch_features = np.zeros((0, sample_shape[0], sample_shape[1], sample_shape[2]), dtype=np.float32)\n",
    "        batch_labels = np.zeros((0, 1), dtype=np.float16)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            idx = np.random.choice(lines_num, 1)[0]\n",
    "            line = csv_lines[idx]\n",
    "\n",
    "            image_center = load_image(line[0])\n",
    "            batch_features = np.append(batch_features, image_center[None,:], axis=0)\n",
    "            batch_labels = np.append(batch_labels, float(line[3]))\n",
    "\n",
    "        yield batch_features, batch_labels\n",
    "\n",
    "def model(csv_lines, batches, batch_size):\n",
    "    epochs = 1\n",
    "    samples_num = len(csv_lines)\n",
    "    generator = build_generator(csv_lines, batches, batch_size)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 1)))\n",
    "    model.add(Conv2D(6, 5, 5, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(6, 5, 5, activation=\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120))\n",
    "    model.add(Dense(84))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit_generator(generator, samples_per_epoch=samples_num, nb_epoch=epochs)\n",
    "#     model.fit(X, y, validation_split=0.2, shuffle=True, nb_epoch=1)\n",
    "\n",
    "    model.save('p3_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "(128, 160, 320, 1) float32 float32\n",
      "(128,) float64 float64\n",
      "(128, 160, 320, 1) float32 float32\n",
      "(128,) float64 float64\n",
      "(128, 160, 320, 1) float32 float32\n",
      "(128,) float64 float64\n",
      "128/256 [==============>...............] - ETA: 12s - loss: 0.0239(128, 160, 320, 1) float32 float32\n",
      "(128,) float64 float64\n",
      "(128, 160, 320, 1) float32 float32\n",
      "(128,) float64 float64\n",
      "256/256 [==============================] - 47s - loss: 105.3036   \n",
      "(128, 160, 320, 1) float32 float32\n",
      "(128,) float64 float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# augmented_images, augmented_steerings = [], []\n",
    "# for image, measuremenet in zip(images_center, measurements):\n",
    "#     augmented_images.append(image)\n",
    "#     augmented_steerings.append(steering)\n",
    "    \n",
    "#     flipped_image = cv2.flip(image, 1)\n",
    "#     augmented_images.append(flipped_image)\n",
    "#     augmented_steerings.append(steering * -1.0)\n",
    "    \n",
    "# X_train = np.array(images_center, dtype=np.float32)\n",
    "# X_train = np.expand_dims(X_train, axis=3)\n",
    "# y_train = np.array(steerings, dtype=np.float16)\n",
    "# print(\"X_train, y_train\", X_train.shape, y_train.shape)\n",
    "\n",
    "def read_csv():\n",
    "    lines = []\n",
    "    with open('../data/driving_log.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "\n",
    "        for i, line in enumerate(reader):\n",
    "            if i != 0:\n",
    "                lines.append(line)\n",
    "                \n",
    "        return lines[:300]\n",
    "    \n",
    "csv_lines = read_csv()\n",
    "lines_num = len(csv_lines)\n",
    "batch_size = 128\n",
    "batches = lines_num // 128\n",
    "lines_num = batch_size * batches\n",
    "csv_lines = csv_lines[:lines_num]\n",
    "    \n",
    "model(csv_lines, batches, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
